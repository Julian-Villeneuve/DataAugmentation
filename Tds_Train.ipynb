{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3508,
     "status": "ok",
     "timestamp": 1670077873414,
     "user": {
      "displayName": "Antoine Lafon",
      "userId": "11270225648262585289"
     },
     "user_tz": -60
    },
    "id": "5df28570"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchnet as tnt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import json\n",
    "import pickle as pkl\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "\n",
    "PATH_AUG = 'augs'\n",
    "sys.path.append( PATH_AUG )\n",
    "import augmentation\n",
    "import cutmix\n",
    "import cutout\n",
    "import mixup\n",
    "import random_shif\n",
    "import windowwarp\n",
    "import get_augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 479,
     "status": "ok",
     "timestamp": 1670077877187,
     "user": {
      "displayName": "Antoine Lafon",
      "userId": "11270225648262585289"
     },
     "user_tz": -60
    },
    "id": "JjDDXBVDFcr3",
    "outputId": "219ae3a3-3cd9-4a2c-880a-ae07e6155b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def augs(BATCH_SIZE, SHAPE, DO_PROB, element_prob):\n",
    "\n",
    "    mix_up = mixup.Mixup(batch_size = BATCH_SIZE,\n",
    "        do_prob = DO_PROB,\n",
    "        sequence_shape = SHAPE[1:],\n",
    "        linear_mix_min = 0.1,\n",
    "        linear_mix_max = 0.5)\n",
    "\n",
    "    cut_mix = cutmix.Cutmix(batch_size = BATCH_SIZE,\n",
    "            do_prob = DO_PROB,\n",
    "            sequence_shape = SHAPE[1:],\n",
    "            min_cutmix_len = SHAPE[1] // 2,\n",
    "            max_cutmix_len = SHAPE[1],\n",
    "            channel_replace_prob = element_prob,\n",
    "            )\n",
    "\n",
    "    cut_mix.batch = BATCH_SIZE\n",
    "    cut_out = cutout.Cutout(\n",
    "            batch_size = BATCH_SIZE,\n",
    "            do_prob = DO_PROB,\n",
    "            sequence_shape = SHAPE[1:],\n",
    "            min_cutout_len = SHAPE[1] // 2,\n",
    "            max_cutout_len = SHAPE[1],\n",
    "            channel_drop_prob = element_prob,\n",
    "    )\n",
    "    \n",
    "    return mix_up, cut_out, cut_mix\n",
    "\n",
    "def batch_aug(x, y, mix_up, cut_out, cut_mix):\n",
    "    example = {'input': x, 'target': y}\n",
    "    example = cut_mix(example)\n",
    "    example = cut_out(example)\n",
    "    example = mix_up(example)\n",
    "    x, y = example['input'], example['target']\n",
    "    return x, y\n",
    "\n",
    "mixUp, cutOut, cutMix = augs( 2, (2, 30, 10, 128, 128), 0.7, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1670077884973,
     "user": {
      "displayName": "Antoine Lafon",
      "userId": "11270225648262585289"
     },
     "user_tz": -60
    },
    "id": "ff63dd2e"
   },
   "outputs": [],
   "source": [
    "PATH_TO_PASTIS = './PASTIS'\n",
    "PATH_TO_PAPS = './utae-paps/'\n",
    "sys.path.append(PATH_TO_PAPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 12429,
     "status": "ok",
     "timestamp": 1670077900049,
     "user": {
      "displayName": "Antoine Lafon",
      "userId": "11270225648262585289"
     },
     "user_tz": -60
    },
    "id": "354f9858"
   },
   "outputs": [],
   "source": [
    "#pastis import\n",
    "#from dataloader import PASTIS_Dataset\n",
    "#from collate import pad_collate\n",
    "\n",
    "#model import\n",
    "import src.model_utils\n",
    "from src.backbones.utae import UTAE\n",
    "from src.learning.miou import *\n",
    "from src.learning.weight_init import *\n",
    "from src import utils\n",
    "\n",
    "from src.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1670077912610,
     "user": {
      "displayName": "Antoine Lafon",
      "userId": "11270225648262585289"
     },
     "user_tz": -60
    },
    "id": "4962a9f0"
   },
   "outputs": [],
   "source": [
    "#pastis function\n",
    "\n",
    "cm = matplotlib.cm.get_cmap('tab20')\n",
    "def_colors = cm.colors\n",
    "cus_colors = ['k'] + [def_colors[i] for i in range(1,20)]+['w']\n",
    "cmap = ListedColormap(colors = cus_colors, name='agri',N=21)\n",
    "\n",
    "def get_rgb(x, batch_index=0, t_show=1):\n",
    "    \"\"\"Utility function to get a displayable rgb image \n",
    "    from a Sentinel-2 time series.\n",
    "    \"\"\"\n",
    "    im = x['S2'][batch_index, t_show, [2,1,0]].cpu().numpy()\n",
    "    mx = im.max(axis=(1,2))\n",
    "    mi = im.min(axis=(1,2))   \n",
    "    im = (im - mi[:,None,None])/(mx - mi)[:,None,None]\n",
    "    im = im.swapaxes(0,2).swapaxes(0,1)\n",
    "    im = np.clip(im, a_max=1, a_min=0)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1670077937195,
     "user": {
      "displayName": "Antoine Lafon",
      "userId": "11270225648262585289"
     },
     "user_tz": -60
    },
    "id": "13a2c7f4"
   },
   "outputs": [],
   "source": [
    "def iterate( model, data_loader, criterion, config, optimizer=None, mode=\"train\", do_augs=False, device=None ):\n",
    "    loss_meter = tnt.meter.AverageValueMeter()\n",
    "    iou_meter = IoU(\n",
    "        num_classes=config[ 'num_classes' ],\n",
    "        ignore_index=config[ 'ignore_index' ],\n",
    "        cm_device=config[ 'device' ],\n",
    "    )\n",
    "\n",
    "    t_start = time.time()\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        \n",
    "        if do_augs:\n",
    "            (x, d), y = batch\n",
    "            print( x.shape )\n",
    "            x, y = batch_aug( x[:, :30, :, :, :], y, mixUp, cutOut, cutMix )\n",
    "            batch = (x, d), y\n",
    "             \n",
    "        if device is not None:\n",
    "            batch = recursive_todevice(batch, device)\n",
    "        (x, dates), y = batch\n",
    "        y = y.long()\n",
    "\n",
    "        if mode != \"train\":\n",
    "            with torch.no_grad():\n",
    "                out = model(x, batch_positions=dates)\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x, batch_positions=dates)\n",
    "        \n",
    "\n",
    "        loss = criterion(out, y)\n",
    "        if mode == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "          \n",
    "        #print( out.shape, y.shape )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = out.argmax(dim=1)\n",
    "        iou_meter.add(pred, y)\n",
    "        loss_meter.add(loss.item())\n",
    "\n",
    "        if (i + 1) % config[ 'display_step' ] == 0:\n",
    "            miou, acc = iou_meter.get_miou_acc()\n",
    "            print(\n",
    "                \"Step [{}/{}], Loss: {:.4f}, Acc : {:.2f}, mIoU {:.2f}\".format(\n",
    "                    i + 1, len(data_loader), loss_meter.value()[0], acc, miou\n",
    "                )\n",
    "            )\n",
    "\n",
    "    t_end = time.time()\n",
    "    total_time = t_end - t_start\n",
    "    print(\"Epoch time : {:.1f}s\".format(total_time))\n",
    "    miou, acc = iou_meter.get_miou_acc()\n",
    "    metrics = {\n",
    "        \"{}_accuracy\".format(mode): acc,\n",
    "        \"{}_loss\".format(mode): loss_meter.value()[0],\n",
    "        \"{}_IoU\".format(mode): miou,\n",
    "        \"{}_epoch_time\".format(mode): total_time,\n",
    "    }\n",
    "\n",
    "    if mode == \"test\":\n",
    "        return metrics, iou_meter.conf_metric.value()  # confusion matrix\n",
    "    else:\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def recursive_todevice(x, device):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.to(device)\n",
    "    elif isinstance(x, dict):\n",
    "        return {k: recursive_todevice(v, device) for k, v in x.items()}\n",
    "    else:\n",
    "        return [recursive_todevice(c, device) for c in x]\n",
    "\n",
    "\n",
    "def prepare_output(config):\n",
    "    os.makedirs(config[ 'res_dir' ], exist_ok=True)\n",
    "    for fold in range(1, 2):\n",
    "        os.makedirs(os.path.join(config[ 'res_dir' ], \"Fold_{}\".format(fold)), exist_ok=True)\n",
    "\n",
    "\n",
    "def checkpoint(fold, log, config):\n",
    "    with open(\n",
    "        os.path.join(config[ 'res_dir' ], \"Fold_{}\".format(fold), \"trainlog.json\"), \"w\"\n",
    "    ) as outfile:\n",
    "        json.dump(log, outfile, indent=4)\n",
    "\n",
    "\n",
    "def save_results(fold, metrics, conf_mat, config):\n",
    "    with open(\n",
    "        os.path.join(config[ 'res_dir' ], \"Fold_{}\".format(fold), \"test_metrics.json\"), \"w\"\n",
    "    ) as outfile:\n",
    "        json.dump(metrics, outfile, indent=4)\n",
    "    pkl.dump(\n",
    "        conf_mat,\n",
    "        open(\n",
    "            os.path.join(config[ 'res_dir' ], \"Fold_{}\".format(fold), \"conf_mat.pkl\"), \"wb\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def overall_performance(config):\n",
    "    cm = np.zeros((config[ 'num_classes' ], config[ 'num_classes' ]))\n",
    "    for fold in range(1, 6):\n",
    "        cm += pkl.load(\n",
    "            open(\n",
    "                os.path.join(config[ 'res_dir' ], \"Fold_{}\".format(fold), \"conf_mat.pkl\"),\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if config.ignore_index is not None:\n",
    "        cm = np.delete(cm, config[ 'ignore_index' ], axis=0)\n",
    "        cm = np.delete(cm, config[ 'ignore_index' ], axis=1)\n",
    "\n",
    "    _, perf = confusion_matrix_analysis(cm)\n",
    "\n",
    "    print(\"Overall performance:\")\n",
    "    print(\"Acc: {},  IoU: {}\".format(perf[\"Accuracy\"], perf[\"MACRO_IoU\"]))\n",
    "\n",
    "    with open(os.path.join(config[ 'res_dir' ], \"overall.json\"), \"w\") as file:\n",
    "        file.write(json.dumps(perf, indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16035,
     "status": "ok",
     "timestamp": 1670077958747,
     "user": {
      "displayName": "Antoine Lafon",
      "userId": "11270225648262585289"
     },
     "user_tz": -60
    },
    "id": "a8ff8bf5",
    "outputId": "b5bfc9bc-837f-42ad-9478-3d8b84b03e75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading patch metadata . . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antoine/Bureau/DataAugmentation/./utae-paps/src/dataset.py:102: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for pid, date_seq in dates.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Dataset ready.\n",
      "Reading patch metadata . . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antoine/Bureau/DataAugmentation/./utae-paps/src/dataset.py:102: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for pid, date_seq in dates.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Dataset ready.\n",
      "Reading patch metadata . . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antoine/Bureau/DataAugmentation/./utae-paps/src/dataset.py:102: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for pid, date_seq in dates.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Dataset ready.\n",
      "981\n",
      "482\n",
      "496\n"
     ]
    }
   ],
   "source": [
    "pad_collate = lambda x: utils.pad_collate(x, pad_value = 0)\n",
    "\n",
    "fold_sequence = [[1, 2], [4], [5]]\n",
    "fold = 0\n",
    "\n",
    "pastis_train_dataset = PASTIS_Dataset(PATH_TO_PASTIS, folds = fold_sequence[ 0 ],  norm=True, target='semantic')\n",
    "pastis_test_dataset  = PASTIS_Dataset(PATH_TO_PASTIS, folds = fold_sequence[ 1 ], norm=True, target='semantic')\n",
    "pastis_eval_dataset = PASTIS_Dataset(PATH_TO_PASTIS, folds = fold_sequence[ 2 ], norm=True, target='semantic')\n",
    "\n",
    "print( len(pastis_train_dataset) )\n",
    "print( len(pastis_test_dataset) )\n",
    "print( len(pastis_eval_dataset) )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(pastis_train_dataset, batch_size=2, collate_fn=pad_collate, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(pastis_test_dataset, batch_size=2, collate_fn=pad_collate, shuffle=True)\n",
    "evaluate_loader = torch.utils.data.DataLoader(pastis_eval_dataset, batch_size=2, collate_fn=pad_collate, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1999,
     "status": "ok",
     "timestamp": 1670077975945,
     "user": {
      "displayName": "Antoine Lafon",
      "userId": "11270225648262585289"
     },
     "user_tz": -60
    },
    "id": "5b245f2f",
    "outputId": "899cb3f5-6e1a-473e-f41c-f7de4b339a78"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antoine/Bureau/DataAugmentation/./utae-paps/src/backbones/positional_encoding.py:12: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  T, 2 * (torch.arange(offset, offset + d).float() // 2) / d\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "config[ 'epoch' ] = 100\n",
    "config[ 'num_classes' ] = 20\n",
    "config[ 'val_after' ] = 0 #nb epoch avant premiere validation\n",
    "config[ 'val_every' ] = 1 #nb epoch entre chaque validation\n",
    "config[ 'device' ] = 'cuda'\n",
    "config[ 'ignore_index' ] = -1\n",
    "config[ 'display_step' ] = 50\n",
    "config[ 'res_dir' ] = './results'\n",
    "config[ 'model' ] = 'utae'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "#torch.cuda.max_split_size_mb( 1024 )\n",
    "\n",
    "model_config = {}\n",
    "\n",
    "model = UTAE(\n",
    "        input_dim = 10,\n",
    "        encoder_widths = [ 64, 64, 64, 128 ],\n",
    "        decoder_widths = [ 32, 32, 64, 128 ],\n",
    "        out_conv = [ 32, 20 ],\n",
    "        str_conv_k = 4,\n",
    "        str_conv_s = 2,\n",
    "        str_conv_p = 1,\n",
    "        agg_mode = \"att_group\",\n",
    "        encoder_norm = \"group\",\n",
    "        n_head = 16,\n",
    "        d_model = 256,\n",
    "        d_k = 4,\n",
    "        encoder = False,\n",
    "        return_maps = False,\n",
    "        pad_value = 0,\n",
    "        padding_mode = \"reflect\",\n",
    "    )\n",
    "\n",
    "device = config[ 'device' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "executionInfo": {
     "elapsed": 39938,
     "status": "error",
     "timestamp": 1670074605927,
     "user": {
      "displayName": "Antoine Lafon",
      "userId": "11270225648262585289"
     },
     "user_tz": -60
    },
    "id": "58a18dbd",
    "outputId": "abe1985c-fe36-45dd-a6f3-c1ac8f86b305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/100\n",
      "torch.Size([2, 43, 10, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antoine/Bureau/DataAugmentation/augs/cutmix.py:74: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  time = torch.range(0, self.sequence_shape[0] - 1, dtype=torch.float32)\n",
      "/home/antoine/Bureau/DataAugmentation/augs/cutout.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  time = torch.range(0, self.sequence_shape[0] - 1, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "HIP out of memory. Tried to allocate 240.00 MiB (GPU 0; 4.00 GiB total capacity; 359.12 MiB already allocated; 3.62 GiB free; 362.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_HIP_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7e5abdb024e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_augs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m'val_every'\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m'val_after'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-2c0682bb876a>\u001b[0m in \u001b[0;36miterate\u001b[0;34m(model, data_loader, criterion, config, optimizer, mode, do_augs, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_positions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bureau/DataAugmentation/./utae-paps/src/backbones/utae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, batch_positions, return_att)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         )  # BxT pad mask\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mfeature_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# SPATIAL ENCODER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bureau/DataAugmentation/./utae-paps/src/backbones/utae.py\u001b[0m in \u001b[0;36msmart_forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mdummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bureau/DataAugmentation/./utae-paps/src/backbones/utae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bureau/DataAugmentation/./utae-paps/src/backbones/utae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         return F.group_norm(\n\u001b[0m\u001b[1;32m    269\u001b[0m             input, self.num_groups, self.weight, self.bias, self.eps)\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2497\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m     \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2499\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: HIP out of memory. Tried to allocate 240.00 MiB (GPU 0; 4.00 GiB total capacity; 359.12 MiB already allocated; 3.62 GiB free; 362.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_HIP_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "prepare_output(config)\n",
    "\n",
    "model = model.to( device )\n",
    "model.apply( weight_init )\n",
    "\n",
    "optimizer = torch.optim.Adam( model.parameters(), lr = 0.001 )\n",
    "\n",
    "weights = torch.ones( config[ 'num_classes' ], device = device ).float()\n",
    "criterion = torch.nn.CrossEntropyLoss( weight = weights )\n",
    "\n",
    "trainlog = {}\n",
    "best_mIoU = 0\n",
    "\n",
    "for e in range( 1, config[ 'epoch' ] + 1 ):\n",
    "    print( \"EPOCH {}/{}\".format( e, config[ 'epoch' ] ) )\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_metrics = iterate( model, train_loader, criterion, config = config, optimizer = optimizer, mode = \"train\", do_augs=True, device = device )\n",
    "    \n",
    "    if e % config[ 'val_every' ] == 0 and e > config[ 'val_after' ]:\n",
    "        print(\"Validation . . . \")\n",
    "        model.eval()\n",
    "        val_metrics = iterate(\n",
    "            model,\n",
    "            data_loader=evaluate_loader,\n",
    "            criterion=criterion,\n",
    "            config=config,\n",
    "            optimizer=optimizer,\n",
    "            mode=\"val\",\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"Loss {:.4f},  Acc {:.2f},  IoU {:.4f}\".format(\n",
    "                val_metrics[\"val_loss\"],\n",
    "                val_metrics[\"val_accuracy\"],\n",
    "                val_metrics[\"val_IoU\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        trainlog[e] = {**train_metrics, **val_metrics}\n",
    "        checkpoint(fold + 1, trainlog, config)\n",
    "        if val_metrics[\"val_IoU\"] >= best_mIoU:\n",
    "            best_mIoU = val_metrics[\"val_IoU\"]\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": e,\n",
    "                    \"state_dict\": model.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                },\n",
    "                os.path.join(\n",
    "                    config[ 'res_dir' ], \"Fold_{}\".format(fold + 1), \"model.pth.tar\"\n",
    "                ),\n",
    "            )\n",
    "    else:\n",
    "        trainlog[e] = { **train_metrics }\n",
    "        checkpoint( fold + 1, trainlog, config )\n",
    "\n",
    "\n",
    "\n",
    "print(\"Testing best epoch . . .\")\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "            os.path.join(\n",
    "            config[ 'res_dir' ], \"Fold_{}\".format(fold + 1), \"model.pth.tar\"\n",
    "    )\n",
    "    )[\"state_dict\"]\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_metrics, conf_mat = iterate(\n",
    "    model,\n",
    "    data_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    config=config,\n",
    "    optimizer=optimizer,\n",
    "    mode=\"test\",\n",
    "    device=device,\n",
    ")\n",
    "print(\n",
    "    \"Loss {:.4f},  Acc {:.2f},  IoU {:.4f}\".format(\n",
    "        test_metrics[\"test_loss\"],\n",
    "        test_metrics[\"test_accuracy\"],\n",
    "        test_metrics[\"test_IoU\"],\n",
    "    )\n",
    ")\n",
    "save_results(1, test_metrics, conf_mat.cpu().numpy(), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1owl5hRGN5CuJoUx3XVbzvNAKwSOQHUFX",
     "timestamp": 1670070041032
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
